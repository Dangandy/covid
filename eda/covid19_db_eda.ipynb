{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "covid19 db eda.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyN020cIcmN6R2Liy/t9fs0X",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dangandy/covid/blob/world-map/eda/covid19_db_eda.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SH5IdHQTRBcH",
        "colab_type": "text"
      },
      "source": [
        "# Install"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHhksLw3S-_k",
        "colab_type": "code",
        "outputId": "5b5d3936-a4a2-4d8e-bf43-2f29ea21d0cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "pip install flask_sqlalchemy"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting flask_sqlalchemy\n",
            "  Downloading https://files.pythonhosted.org/packages/1e/65/226d95466c75e34e291a76890ed0e27af2e46ab913002847856f11d4d59d/Flask_SQLAlchemy-2.4.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: SQLAlchemy>=0.8.0 in /usr/local/lib/python3.6/dist-packages (from flask_sqlalchemy) (1.3.16)\n",
            "Requirement already satisfied: Flask>=0.10 in /usr/local/lib/python3.6/dist-packages (from flask_sqlalchemy) (1.1.2)\n",
            "Requirement already satisfied: Werkzeug>=0.15 in /usr/local/lib/python3.6/dist-packages (from Flask>=0.10->flask_sqlalchemy) (1.0.1)\n",
            "Requirement already satisfied: Jinja2>=2.10.1 in /usr/local/lib/python3.6/dist-packages (from Flask>=0.10->flask_sqlalchemy) (2.11.2)\n",
            "Requirement already satisfied: click>=5.1 in /usr/local/lib/python3.6/dist-packages (from Flask>=0.10->flask_sqlalchemy) (7.1.1)\n",
            "Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.6/dist-packages (from Flask>=0.10->flask_sqlalchemy) (1.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.10.1->Flask>=0.10->flask_sqlalchemy) (1.1.1)\n",
            "Installing collected packages: flask-sqlalchemy\n",
            "Successfully installed flask-sqlalchemy-2.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qgZQrtbyiWo0",
        "colab_type": "text"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MgFUiLqViVDn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# db model\n",
        "from flask import Flask\n",
        "from flask_sqlalchemy import SQLAlchemy\n",
        "\n",
        "# create\n",
        "from datetime import datetime, timedelta\n",
        "import requests\n",
        "\n",
        "# lstm\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random as rn\n",
        "\n",
        "# model\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dense\n",
        "from keras.losses import MeanSquaredLogarithmicError\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# predict\n",
        "from keras.models import load_model\n",
        "import collections"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J4gwFxd_ibPN",
        "colab_type": "text"
      },
      "source": [
        "# db model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGaALGgKS78u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load flask\n",
        "app = Flask(__name__)\n",
        "app.config[\"SQLALCHEMY_DATABASE_URI\"] = \"sqlite:///site.db\"\n",
        "app.config[\"SQLALCHEMY_TRACK_MODIFICATIONS\"] = False\n",
        "\n",
        "# load db\n",
        "db = SQLAlchemy(app)\n",
        "\n",
        "# db models\n",
        "class Stat(db.Model):\n",
        "    id = db.Column(db.String(120), primary_key=True)\n",
        "    country = db.Column(db.String(100), unique=False, nullable=False)\n",
        "    date = db.Column(db.Date, nullable=False)\n",
        "    confirmed = db.Column(db.Integer)\n",
        "    deaths = db.Column(db.Integer)\n",
        "    recovered = db.Column(db.Integer)\n",
        "    confirmed_pred = db.Column(db.Integer)\n",
        "    deaths_pred = db.Column(db.Integer)\n",
        "    recovered_pred = db.Column(db.Integer)\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f\"Stat('{self.country}', '{self.date}', '{self.confirmed}', '{self.deaths}', '{self.recovered}',  '{self.confirmed_pred}', '{self.deaths_pred}', '{self.recovered_pred}')\"\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MKGly5ueinPM",
        "colab_type": "text"
      },
      "source": [
        "# create"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xFNN-2hXSz1Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Create:\n",
        "    def __init__(self):\n",
        "        # variables\n",
        "        self.url = \"https://pomber.github.io/covid19/timeseries.json\"\n",
        "\n",
        "    def extract(self):\n",
        "        # get json data\n",
        "        response = requests.get(self.url)\n",
        "        json = response.json()\n",
        "\n",
        "        # return\n",
        "        return json\n",
        "\n",
        "    def transform(self, json: dict):\n",
        "        # variables\n",
        "        countries = json.keys()\n",
        "        all_data = []\n",
        "\n",
        "        # loop\n",
        "        for country in countries:\n",
        "\n",
        "            # build array of json\n",
        "            for i, stat in enumerate(json[country]):\n",
        "                date = datetime.strptime(stat[\"date\"], \"%Y-%m-%d\").date()\n",
        "                data = Stat(\n",
        "                    id=f\"{country}{date}\",\n",
        "                    country=country,\n",
        "                    date= date,\n",
        "                    confirmed=stat[\"confirmed\"],\n",
        "                    deaths=stat[\"deaths\"],\n",
        "                    recovered=stat[\"recovered\"],\n",
        "                )\n",
        "                all_data.append(data)\n",
        "\n",
        "        # return\n",
        "        return all_data\n",
        "\n",
        "    def load(self, data):\n",
        "        # create db\n",
        "        db.create_all()\n",
        "\n",
        "        # add to db\n",
        "        db.session.bulk_save_objects(data)\n",
        "        db.session.commit()\n",
        "\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    1. Extract JSON from url\n",
        "    2. Transform JSON into: id, country, confirmed, recovered, deaths\n",
        "        - id is in the form of {country}{date}\n",
        "    3. Load object into sqlite database\n",
        "    \"\"\"\n",
        "    create = Create()\n",
        "    json = create.extract()\n",
        "    data = create.transform(json)\n",
        "    create.load(data)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W0-HNWAti1OR",
        "colab_type": "text"
      },
      "source": [
        "# Update"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8pgVz60Ji1-5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Update(Create):\n",
        "    def transform(self, json: dict):\n",
        "        # variables\n",
        "        countries = json.keys()\n",
        "        update_data = []\n",
        "\n",
        "        # we only want to update everything from yesterday onwards..\n",
        "        update_day = datetime.now().date() + timedelta(days=-1)\n",
        "\n",
        "        # loop and build array of Stat\n",
        "        for country in countries:\n",
        "            for i, stat in enumerate(json[country]):\n",
        "                date = datetime.strptime(stat[\"date\"], \"%Y-%m-%d\").date()\n",
        "\n",
        "                if date >= update_day:\n",
        "                    update_data.append(\n",
        "                        Stat(\n",
        "                            id=f\"{country}{date}\",\n",
        "                            country=country,\n",
        "                            date=date,\n",
        "                            confirmed=stat[\"confirmed\"],\n",
        "                            deaths=stat[\"deaths\"],\n",
        "                            recovered=stat[\"recovered\"],\n",
        "                        )\n",
        "                    )\n",
        "\n",
        "        # return\n",
        "        return update_data\n",
        "\n",
        "    def load(self, data):\n",
        "        \"\"\"\n",
        "        insert if doesn't exist, update otherwise\n",
        "        \"\"\"\n",
        "        # loop\n",
        "        for stat in data:\n",
        "            query = Stat.query.get({\"id\": stat.id})\n",
        "            if query:\n",
        "                query.confirmed = stat.confirmed\n",
        "                query.deaths = stat.deaths\n",
        "                query.recovered = stat.recovered\n",
        "            else:\n",
        "                db.session.add(stat)\n",
        "\n",
        "        # commit\n",
        "        db.session.commit()\n",
        "\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    1. Extract new data from url\n",
        "    2. get last 2 days data ( data here is updated hourly )\n",
        "    3. insert / update into db\n",
        "    \"\"\"\n",
        "    update = Update()\n",
        "    json = update.extract()\n",
        "    last_days = update.transform(json)\n",
        "    update.load(last_days)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Yel-EWmS6-F",
        "colab_type": "text"
      },
      "source": [
        "# build lstm model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1fYQrZRTTM-I",
        "colab_type": "code",
        "outputId": "3caa0c6b-0766-4e1e-851a-1d065f032c83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "class Lstm:\n",
        "    def extract(self) -> pd.DataFrame:\n",
        "        \"\"\"\n",
        "        extract data from database and output into dataframe\n",
        "        \"\"\"\n",
        "        # grab all record from stat table\n",
        "        df = pd.read_sql_table(\"stat\", \"sqlite:///site.db\")\n",
        "\n",
        "        # return\n",
        "        return df\n",
        "\n",
        "    def transform(self, df: pd.DataFrame) -> pd.DataFrame:\n",
        "        \"\"\"\n",
        "        transforms done to dataframe:\n",
        "        - calculate the difference of each metric\n",
        "        - onehotencode countries\n",
        "        \"\"\"\n",
        "        # get diff\n",
        "        df[\"confirmed_diff\"] = np.where(\n",
        "            df.country == df.country.shift(), df.confirmed - df.confirmed.shift(), 0\n",
        "        )\n",
        "        df[\"recovered_diff\"] = np.where(\n",
        "            df.country == df.country.shift(), df.recovered - df.recovered.shift(), 0\n",
        "        )\n",
        "        df[\"deaths_diff\"] = np.where(\n",
        "            df.country == df.country.shift(), df.deaths - df.deaths.shift(), 0\n",
        "        )\n",
        "\n",
        "        # encode country with pd.dummies\n",
        "        dummies = pd.get_dummies(df.country)\n",
        "        dummies[\"id\"] = df.id\n",
        "        df = pd.merge(df, dummies, on=[\"id\"])\n",
        "\n",
        "        # return\n",
        "        return df\n",
        "\n",
        "    def load(\n",
        "        self,\n",
        "        df: pd.DataFrame,\n",
        "        metric=\"confirmed\",\n",
        "        win_size=7,\n",
        "        epochs=5,\n",
        "        batch_size=32,\n",
        "        save=False,\n",
        "    ) -> Sequential:\n",
        "        \"\"\"\n",
        "        load dataframe into sequential\n",
        "        \"\"\"\n",
        "        # variables\n",
        "        x, y = [], []\n",
        "        countries = db.session.query(Stat.country).distinct().all()\n",
        "\n",
        "        # countries come in the form of [('Afghanistan',), ('Albania',), ... ]\n",
        "        for (country,) in countries:\n",
        "            country_df = df[df.country == country]\n",
        "            series = list(country_df[metric])\n",
        "            for i in range(0, len(series) - win_size):\n",
        "                end = i + win_size\n",
        "                series_x, series_y = series[i:end], series[end]\n",
        "                if series_y:\n",
        "                    x.append(series_x)\n",
        "                    y.append(series_y)\n",
        "        X, y = np.array(x), np.array(y)\n",
        "\n",
        "        # TTS\n",
        "        X_train, X_val, y_train, y_val = train_test_split(\n",
        "            X, y, test_size=0.2, random_state=42\n",
        "        )\n",
        "\n",
        "        # preprocess\n",
        "        X_train = X_train.reshape(X_train.shape[0], 1, X_train.shape[1])\n",
        "        X_val = X_val.reshape(X_val.shape[0], 1, X_val.shape[1])\n",
        "\n",
        "        # build model\n",
        "        model = Sequential()\n",
        "        model.add(\n",
        "            LSTM(\n",
        "                100,\n",
        "                activation=\"relu\",\n",
        "                input_shape=(1, win_size),\n",
        "                return_sequences=True,\n",
        "            )\n",
        "        )\n",
        "        model.add(LSTM(150, activation=\"relu\"))\n",
        "        model.add(Dense(1, activation=\"relu\"))\n",
        "\n",
        "        # Compile Model\n",
        "        model.compile(optimizer=\"adam\", loss=MeanSquaredLogarithmicError())\n",
        "\n",
        "        # Fit Model\n",
        "        model.fit(\n",
        "            X_train,\n",
        "            y_train,\n",
        "            epochs=epochs,\n",
        "            batch_size=batch_size,\n",
        "            validation_data=(X_val, y_val),\n",
        "            verbose=2,\n",
        "            shuffle=True,\n",
        "        )\n",
        "\n",
        "        # Export Model\n",
        "        if save:\n",
        "            model.save(\"lstm_model.h5\")\n",
        "\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    run code\n",
        "    \"\"\"\n",
        "    # Set random state for Keras\n",
        "    np.random.seed(42)\n",
        "    rn.seed(12345)\n",
        "\n",
        "    # build model and save it\n",
        "    model = Lstm()\n",
        "    df = model.extract()\n",
        "    df = model.transform(df)\n",
        "    lstm = model.load(df, save=True)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 7503 samples, validate on 1876 samples\n",
            "Epoch 1/5\n",
            " - 2s - loss: 1.6263 - val_loss: 0.0317\n",
            "Epoch 2/5\n",
            " - 1s - loss: 0.0385 - val_loss: 0.0302\n",
            "Epoch 3/5\n",
            " - 1s - loss: 0.0372 - val_loss: 0.0304\n",
            "Epoch 4/5\n",
            " - 1s - loss: 0.0365 - val_loss: 0.0289\n",
            "Epoch 5/5\n",
            " - 1s - loss: 0.0361 - val_loss: 0.0297\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IkDoEMhuS0SE",
        "colab_type": "text"
      },
      "source": [
        "## predict"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sY_i90ZPT-Um",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Predict:\n",
        "    def __init__(self):\n",
        "        # start date is 7 days ago\n",
        "        self.today = datetime.now().date()\n",
        "        self.start_date = self.today + timedelta(days=-7)\n",
        "\n",
        "    def get_data(self):\n",
        "        \"\"\"\n",
        "        get last \"7\" days of data\n",
        "        \"\"\"\n",
        "        # get all prediction of country\n",
        "        result = Stat.query.filter(\n",
        "            Stat.date >= self.start_date, Stat.date < self.today\n",
        "        ).all()\n",
        "\n",
        "        # create a map for each country and their 7 latest record\n",
        "        memo = collections.defaultdict(list)\n",
        "        for stat in result:\n",
        "            memo[stat.country].append(stat.confirmed)\n",
        "\n",
        "        # return\n",
        "        countries = memo.keys()\n",
        "        X = np.array([memo[country] for country in countries])\n",
        "        X = X.reshape(X.shape[0], 1, X.shape[1])\n",
        "        return countries, X\n",
        "\n",
        "    def predict(self, countries, X, model):\n",
        "        \"\"\"\n",
        "        predict, then predict again\n",
        "        \"\"\"\n",
        "        # variables\n",
        "        data = []\n",
        "\n",
        "        # predict - we'll be shifting x every iteration because predict output 1 value\n",
        "        for i in range(7):\n",
        "            _X = np.array([x[i : 7 + i] for [x] in X])\n",
        "            _X = _X.reshape(_X.shape[0], 1, _X.shape[1])\n",
        "            y_pred = model.predict(_X)\n",
        "\n",
        "            # add new prediction to x\n",
        "            X = np.array([np.append(x, y_pred[j]) for j, [x] in enumerate(X)])\n",
        "            X = X.reshape(X.shape[0], 1, X.shape[1])\n",
        "\n",
        "        # add predictions into database..\n",
        "        y_pred = [x[7:14] for [x] in X]\n",
        "        for country, prediction in zip(countries, y_pred):\n",
        "            for i, pred in enumerate(prediction):\n",
        "                pred_date = self.today + timedelta(days=i)\n",
        "                data.append(\n",
        "                    Stat(\n",
        "                        id=f\"{country}{pred_date}\",\n",
        "                        country=country,\n",
        "                        date=pred_date,\n",
        "                        confirmed_pred=int(pred),\n",
        "                    )\n",
        "                )\n",
        "\n",
        "        # return\n",
        "        return data\n",
        "\n",
        "    def load(self, data):\n",
        "        \"\"\"\n",
        "        insert if doesn't exist, update otherwise\n",
        "        \"\"\"\n",
        "        # loop\n",
        "        for stat in data:\n",
        "            query = Stat.query.get({\"id\": stat.id})\n",
        "            if query:\n",
        "                query.confirmed = stat.confirmed\n",
        "                query.deaths = stat.deaths\n",
        "                query.recovered = stat.recovered\n",
        "                query.confirmed_pred = (\n",
        "                    stat.confirmed_pred if stat.confirmed_pred else None\n",
        "                )\n",
        "                query.deaths_pred = stat.deaths_pred if stat.deaths_pred else None\n",
        "                query.recovered_pred = (\n",
        "                    stat.recovered_pred if stat.recovered_pred else None\n",
        "                )\n",
        "            else:\n",
        "                db.session.add(stat)\n",
        "\n",
        "        # commit\n",
        "        db.session.commit()\n",
        "\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    run code\n",
        "    \"\"\"\n",
        "    # variables\n",
        "    predict = Predict()\n",
        "\n",
        "    # load model\n",
        "    lstm = load_model(\"lstm_model.h5\")\n",
        "    countries, X = predict.get_data()\n",
        "    data = predict.predict(countries, X, lstm)\n",
        "\n",
        "    # save to db\n",
        "    predict.load(data)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZfLliD9fwIQ",
        "colab_type": "text"
      },
      "source": [
        "### predict china"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4wNGjFZrfx-i",
        "colab_type": "text"
      },
      "source": [
        "Here, it should be flattening.. lets see if the algorithm can predict this.."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGVrltwFf0Rf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e6e32934-4c03-43b5-f7b5-5acb0484b440"
      },
      "source": [
        "Stat.query.filter_by(country='China').all()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Stat('China', '2020-01-22', '548', '17', '28',  'None', 'None', 'None'),\n",
              " Stat('China', '2020-01-23', '643', '18', '30',  'None', 'None', 'None'),\n",
              " Stat('China', '2020-01-24', '920', '26', '36',  'None', 'None', 'None'),\n",
              " Stat('China', '2020-01-25', '1406', '42', '39',  'None', 'None', 'None'),\n",
              " Stat('China', '2020-01-26', '2075', '56', '49',  'None', 'None', 'None'),\n",
              " Stat('China', '2020-01-27', '2877', '82', '58',  'None', 'None', 'None'),\n",
              " Stat('China', '2020-01-28', '5509', '131', '101',  'None', 'None', 'None'),\n",
              " Stat('China', '2020-01-29', '6087', '133', '120',  'None', 'None', 'None'),\n",
              " Stat('China', '2020-01-30', '8141', '171', '135',  'None', 'None', 'None'),\n",
              " Stat('China', '2020-01-31', '9802', '213', '214',  'None', 'None', 'None'),\n",
              " Stat('China', '2020-02-01', '11891', '259', '275',  'None', 'None', 'None'),\n",
              " Stat('China', '2020-02-02', '16630', '361', '463',  'None', 'None', 'None'),\n",
              " Stat('China', '2020-02-03', '19716', '425', '614',  'None', 'None', 'None'),\n",
              " Stat('China', '2020-02-04', '23707', '491', '843',  'None', 'None', 'None'),\n",
              " Stat('China', '2020-02-05', '27440', '563', '1115',  'None', 'None', 'None'),\n",
              " Stat('China', '2020-02-06', '30587', '633', '1477',  'None', 'None', 'None'),\n",
              " Stat('China', '2020-02-07', '34110', '718', '1999',  'None', 'None', 'None'),\n",
              " Stat('China', '2020-02-08', '36814', '805', '2596',  'None', 'None', 'None'),\n",
              " Stat('China', '2020-02-09', '39829', '905', '3219',  'None', 'None', 'None'),\n",
              " Stat('China', '2020-02-10', '42354', '1012', '3918',  'None', 'None', 'None'),\n",
              " Stat('China', '2020-02-11', '44386', '1112', '4636',  'None', 'None', 'None'),\n",
              " Stat('China', '2020-02-12', '44759', '1117', '5082',  'None', 'None', 'None'),\n",
              " Stat('China', '2020-02-13', '59895', '1369', '6217',  'None', 'None', 'None'),\n",
              " Stat('China', '2020-02-14', '66358', '1521', '7977',  'None', 'None', 'None'),\n",
              " Stat('China', '2020-02-15', '68413', '1663', '9298',  'None', 'None', 'None'),\n",
              " Stat('China', '2020-02-16', '70513', '1766', '10755',  'None', 'None', 'None'),\n",
              " Stat('China', '2020-02-17', '72434', '1864', '12462',  'None', 'None', 'None'),\n",
              " Stat('China', '2020-02-18', '74211', '2003', '14206',  'None', 'None', 'None'),\n",
              " Stat('China', '2020-02-19', '74619', '2116', '15962',  'None', 'None', 'None'),\n",
              " Stat('China', '2020-02-20', '75077', '2238', '18014',  'None', 'None', 'None'),\n",
              " Stat('China', '2020-02-21', '75550', '2238', '18704',  'None', 'None', 'None'),\n",
              " Stat('China', '2020-02-22', '77001', '2443', '22699',  'None', 'None', 'None'),\n",
              " Stat('China', '2020-02-23', '77022', '2445', '23187',  'None', 'None', 'None'),\n",
              " Stat('China', '2020-02-24', '77241', '2595', '25015',  'None', 'None', 'None'),\n",
              " Stat('China', '2020-02-25', '77754', '2665', '27676',  'None', 'None', 'None'),\n",
              " Stat('China', '2020-02-26', '78166', '2717', '30084',  'None', 'None', 'None'),\n",
              " Stat('China', '2020-02-27', '78600', '2746', '32930',  'None', 'None', 'None'),\n",
              " Stat('China', '2020-02-28', '78928', '2790', '36329',  'None', 'None', 'None'),\n",
              " Stat('China', '2020-02-29', '79356', '2837', '39320',  'None', 'None', 'None'),\n",
              " Stat('China', '2020-03-01', '79932', '2872', '42162',  'None', 'None', 'None'),\n",
              " Stat('China', '2020-03-02', '80136', '2914', '44854',  'None', 'None', 'None'),\n",
              " Stat('China', '2020-03-03', '80261', '2947', '47450',  'None', 'None', 'None'),\n",
              " Stat('China', '2020-03-04', '80386', '2983', '50001',  'None', 'None', 'None'),\n",
              " Stat('China', '2020-03-05', '80537', '3015', '52292',  'None', 'None', 'None'),\n",
              " Stat('China', '2020-03-06', '80690', '3044', '53944',  'None', 'None', 'None'),\n",
              " Stat('China', '2020-03-07', '80770', '3072', '55539',  'None', 'None', 'None'),\n",
              " Stat('China', '2020-03-08', '80823', '3100', '57388',  'None', 'None', 'None'),\n",
              " Stat('China', '2020-03-09', '80860', '3123', '58804',  'None', 'None', 'None'),\n",
              " Stat('China', '2020-03-10', '80887', '3139', '60181',  'None', 'None', 'None'),\n",
              " Stat('China', '2020-03-11', '80921', '3161', '61644',  'None', 'None', 'None'),\n",
              " Stat('China', '2020-03-12', '80932', '3172', '62901',  'None', 'None', 'None'),\n",
              " Stat('China', '2020-03-13', '80945', '3180', '64196',  'None', 'None', 'None'),\n",
              " Stat('China', '2020-03-14', '80977', '3193', '65660',  'None', 'None', 'None'),\n",
              " Stat('China', '2020-03-15', '81003', '3203', '67017',  'None', 'None', 'None'),\n",
              " Stat('China', '2020-03-16', '81033', '3217', '67910',  'None', 'None', 'None'),\n",
              " Stat('China', '2020-03-17', '81058', '3230', '68798',  'None', 'None', 'None'),\n",
              " Stat('China', '2020-03-18', '81102', '3241', '69755',  'None', 'None', 'None'),\n",
              " Stat('China', '2020-03-19', '81156', '3249', '70535',  'None', 'None', 'None'),\n",
              " Stat('China', '2020-03-20', '81250', '3253', '71266',  'None', 'None', 'None'),\n",
              " Stat('China', '2020-03-21', '81305', '3259', '71857',  'None', 'None', 'None'),\n",
              " Stat('China', '2020-03-22', '81435', '3274', '72362',  'None', 'None', 'None'),\n",
              " Stat('China', '2020-03-23', '81498', '3274', '72814',  'None', 'None', 'None'),\n",
              " Stat('China', '2020-03-24', '81591', '3281', '73280',  'None', 'None', 'None'),\n",
              " Stat('China', '2020-03-25', '81661', '3285', '73773',  'None', 'None', 'None'),\n",
              " Stat('China', '2020-03-26', '81782', '3291', '74181',  'None', 'None', 'None'),\n",
              " Stat('China', '2020-03-27', '81897', '3296', '74720',  'None', 'None', 'None'),\n",
              " Stat('China', '2020-03-28', '81999', '3299', '75100',  'None', 'None', 'None'),\n",
              " Stat('China', '2020-03-29', '82122', '3304', '75582',  'None', 'None', 'None'),\n",
              " Stat('China', '2020-03-30', '82198', '3308', '75923',  'None', 'None', 'None'),\n",
              " Stat('China', '2020-03-31', '82279', '3309', '76206',  'None', 'None', 'None'),\n",
              " Stat('China', '2020-04-01', '82361', '3316', '76405',  'None', 'None', 'None'),\n",
              " Stat('China', '2020-04-02', '82432', '3322', '76565',  'None', 'None', 'None'),\n",
              " Stat('China', '2020-04-03', '82511', '3326', '76760',  'None', 'None', 'None'),\n",
              " Stat('China', '2020-04-04', '82543', '3330', '76946',  'None', 'None', 'None'),\n",
              " Stat('China', '2020-04-05', '82602', '3333', '77207',  'None', 'None', 'None'),\n",
              " Stat('China', '2020-04-06', '82665', '3335', '77310',  'None', 'None', 'None'),\n",
              " Stat('China', '2020-04-07', '82718', '3335', '77410',  'None', 'None', 'None'),\n",
              " Stat('China', '2020-04-08', '82809', '3337', '77567',  'None', 'None', 'None'),\n",
              " Stat('China', '2020-04-09', '82883', '3339', '77679',  'None', 'None', 'None'),\n",
              " Stat('China', '2020-04-10', '82941', '3340', '77791',  'None', 'None', 'None'),\n",
              " Stat('China', '2020-04-11', '83014', '3343', '77877',  'None', 'None', 'None'),\n",
              " Stat('China', '2020-04-12', '83134', '3343', '77956',  'None', 'None', 'None'),\n",
              " Stat('China', '2020-04-13', '83213', '3345', '78039',  'None', 'None', 'None'),\n",
              " Stat('China', '2020-04-14', '83306', '3345', '78200',  'None', 'None', 'None'),\n",
              " Stat('China', '2020-04-15', '83356', '3346', '78311',  'None', 'None', 'None'),\n",
              " Stat('China', '2020-04-16', '83403', '3346', '78401',  'None', 'None', 'None'),\n",
              " Stat('China', '2020-04-17', '83760', '4636', '77552',  'None', 'None', 'None'),\n",
              " Stat('China', '2020-04-18', '83787', '4636', '77614',  'None', 'None', 'None'),\n",
              " Stat('China', '2020-04-19', '83805', '4636', '77690',  'None', 'None', 'None'),\n",
              " Stat('China', '2020-04-20', '83817', '4636', '77745',  'None', 'None', 'None'),\n",
              " Stat('China', '2020-04-21', '83853', '4636', '77799',  'None', 'None', 'None'),\n",
              " Stat('China', '2020-04-22', '83868', '4636', '77861',  'None', 'None', 'None'),\n",
              " Stat('China', '2020-04-23', '83884', '4636', '77983',  'None', 'None', 'None'),\n",
              " Stat('China', '2020-04-24', 'None', 'None', 'None',  '89204', 'None', 'None'),\n",
              " Stat('China', '2020-04-25', 'None', 'None', 'None',  '93657', 'None', 'None'),\n",
              " Stat('China', '2020-04-26', 'None', 'None', 'None',  '98689', 'None', 'None'),\n",
              " Stat('China', '2020-04-27', 'None', 'None', 'None',  '105905', 'None', 'None'),\n",
              " Stat('China', '2020-04-28', 'None', 'None', 'None',  '113670', 'None', 'None'),\n",
              " Stat('China', '2020-04-29', 'None', 'None', 'None',  '122862', 'None', 'None'),\n",
              " Stat('China', '2020-04-30', 'None', 'None', 'None',  '133315', 'None', 'None')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SreC-DmbmIif",
        "colab_type": "text"
      },
      "source": [
        "# api methods"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sRP9qiCY1WGX",
        "colab_type": "text"
      },
      "source": [
        "Broken up by individual functions because we can't use flask here\n",
        "\n",
        "Using 'Canada' as default"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_p0YBDED154i",
        "colab_type": "text"
      },
      "source": [
        "## Country Stats"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bP9GqM-j13kr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# search db\n",
        "    result = (\n",
        "        Stat.query.filter(Stat.confirmed != None, Stat.country == 'Canada')\n",
        "        .order_by(Stat.date.desc())\n",
        "        .first()\n",
        "    )\n",
        "\n",
        "{\n",
        "\"confirmed\": result.confirmed,\n",
        "    \"deaths\": result.deaths,\n",
        "    \"recovered\": result.recovered,\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k0VE-eBM2HZj",
        "colab_type": "text"
      },
      "source": [
        "## World Stats"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6FKAy4jj2ITy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# search db\n",
        "result = (\n",
        "    db.session.query(\n",
        "        db.func.max(Stat.confirmed).label(\"confirmed\"),\n",
        "        db.func.max(Stat.recovered).label(\"recovered\"),\n",
        "        db.func.max(Stat.deaths).label(\"deaths\"),\n",
        "    )\n",
        "    .filter(Stat.confirmed != None)\n",
        "    .order_by(Stat.date.desc())\n",
        "    .group_by(Stat.country)\n",
        "    .all()\n",
        ")\n",
        "\n",
        "# get sums because I don't know how to do it in SQLAlchemy..\n",
        "confirmed = sum(r[0] for r in result)\n",
        "recovered = sum(r[1] for r in result)\n",
        "deaths = sum(r[2] for r in result)\n",
        "\n",
        "# return\n",
        "{\"confirmed\": confirmed, \"recovered\": recovered, \"deaths\": deaths}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fGHeVvLO2SXg",
        "colab_type": "text"
      },
      "source": [
        "## Country history"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_tWijrz62UAP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# varialbes\n",
        "array = []\n",
        "\n",
        "# use filter to get all data\n",
        "result = Stat.query.filter_by(country='Canada').all()\n",
        "\n",
        "# build array\n",
        "for record in result:\n",
        "    array.append(\n",
        "        {\n",
        "            \"confirmed\": record.confirmed,\n",
        "            \"date\": record.date,\n",
        "            \"recovered\": record.recovered,\n",
        "            \"deaths\": record.deaths,\n",
        "            \"confirmed_pred\": record.confirmed_pred,\n",
        "        }\n",
        "    )\n",
        "\n",
        "# return\n",
        "{\"result\": array[:3]}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MM4osaU2jGo",
        "colab_type": "text"
      },
      "source": [
        "## World History"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXlq-d59z_xM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# variables\n",
        "array = []\n",
        "\n",
        "# query\n",
        "result = (\n",
        "    db.session.query(\n",
        "        Stat.country,\n",
        "        db.func.max(Stat.confirmed).label(\"confirmed\"),\n",
        "        Stat.recovered,\n",
        "        Stat.deaths,\n",
        "        Stat.confirmed_pred,\n",
        "    )\n",
        "    .group_by(Stat.country)\n",
        "    .all()\n",
        ")\n",
        "\n",
        "# build array\n",
        "for record in result:\n",
        "    array.append(\n",
        "        {\n",
        "            \"country\": record.country,\n",
        "            \"confirmed\": record.confirmed,\n",
        "            \"recovered\": record.recovered,\n",
        "            \"deaths\": record.deaths,\n",
        "            \"confirmed_pred\": record.confirmed_pred,\n",
        "        }\n",
        "    )\n",
        "\n",
        "# return\n",
        "{\"result\": array[-5:]}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tSzfqlxhh4WF",
        "colab_type": "text"
      },
      "source": [
        "## Get all country names"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5goTnDrh6MD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "69e54058-0e37-4077-c631-f818f150b407"
      },
      "source": [
        "db.session.query(\n",
        "    Stat.country.distinct()\n",
        ").all()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Afghanistan'),\n",
              " ('Albania'),\n",
              " ('Algeria'),\n",
              " ('Andorra'),\n",
              " ('Angola'),\n",
              " ('Antigua and Barbuda'),\n",
              " ('Argentina'),\n",
              " ('Armenia'),\n",
              " ('Australia'),\n",
              " ('Austria'),\n",
              " ('Azerbaijan'),\n",
              " ('Bahamas'),\n",
              " ('Bahrain'),\n",
              " ('Bangladesh'),\n",
              " ('Barbados'),\n",
              " ('Belarus'),\n",
              " ('Belgium'),\n",
              " ('Benin'),\n",
              " ('Bhutan'),\n",
              " ('Bolivia'),\n",
              " ('Bosnia and Herzegovina'),\n",
              " ('Brazil'),\n",
              " ('Brunei'),\n",
              " ('Bulgaria'),\n",
              " ('Burkina Faso'),\n",
              " ('Cabo Verde'),\n",
              " ('Cambodia'),\n",
              " ('Cameroon'),\n",
              " ('Canada'),\n",
              " ('Central African Republic'),\n",
              " ('Chad'),\n",
              " ('Chile'),\n",
              " ('China'),\n",
              " ('Colombia'),\n",
              " ('Congo (Brazzaville)'),\n",
              " ('Congo (Kinshasa)'),\n",
              " ('Costa Rica'),\n",
              " (\"Cote d'Ivoire\"),\n",
              " ('Croatia'),\n",
              " ('Diamond Princess'),\n",
              " ('Cuba'),\n",
              " ('Cyprus'),\n",
              " ('Czechia'),\n",
              " ('Denmark'),\n",
              " ('Djibouti'),\n",
              " ('Dominican Republic'),\n",
              " ('Ecuador'),\n",
              " ('Egypt'),\n",
              " ('El Salvador'),\n",
              " ('Equatorial Guinea'),\n",
              " ('Eritrea'),\n",
              " ('Estonia'),\n",
              " ('Eswatini'),\n",
              " ('Ethiopia'),\n",
              " ('Fiji'),\n",
              " ('Finland'),\n",
              " ('France'),\n",
              " ('Gabon'),\n",
              " ('Gambia'),\n",
              " ('Georgia'),\n",
              " ('Germany'),\n",
              " ('Ghana'),\n",
              " ('Greece'),\n",
              " ('Guatemala'),\n",
              " ('Guinea'),\n",
              " ('Guyana'),\n",
              " ('Haiti'),\n",
              " ('Holy See'),\n",
              " ('Honduras'),\n",
              " ('Hungary'),\n",
              " ('Iceland'),\n",
              " ('India'),\n",
              " ('Indonesia'),\n",
              " ('Iran'),\n",
              " ('Iraq'),\n",
              " ('Ireland'),\n",
              " ('Israel'),\n",
              " ('Italy'),\n",
              " ('Jamaica'),\n",
              " ('Japan'),\n",
              " ('Jordan'),\n",
              " ('Kazakhstan'),\n",
              " ('Kenya'),\n",
              " ('Korea, South'),\n",
              " ('Kuwait'),\n",
              " ('Kyrgyzstan'),\n",
              " ('Latvia'),\n",
              " ('Lebanon'),\n",
              " ('Liberia'),\n",
              " ('Liechtenstein'),\n",
              " ('Lithuania'),\n",
              " ('Luxembourg'),\n",
              " ('Madagascar'),\n",
              " ('Malaysia'),\n",
              " ('Maldives'),\n",
              " ('Malta'),\n",
              " ('Mauritania'),\n",
              " ('Mauritius'),\n",
              " ('Mexico'),\n",
              " ('Moldova'),\n",
              " ('Monaco'),\n",
              " ('Mongolia'),\n",
              " ('Montenegro'),\n",
              " ('Morocco'),\n",
              " ('Namibia'),\n",
              " ('Nepal'),\n",
              " ('Netherlands'),\n",
              " ('New Zealand'),\n",
              " ('Nicaragua'),\n",
              " ('Niger'),\n",
              " ('Nigeria'),\n",
              " ('North Macedonia'),\n",
              " ('Norway'),\n",
              " ('Oman'),\n",
              " ('Pakistan'),\n",
              " ('Panama'),\n",
              " ('Papua New Guinea'),\n",
              " ('Paraguay'),\n",
              " ('Peru'),\n",
              " ('Philippines'),\n",
              " ('Poland'),\n",
              " ('Portugal'),\n",
              " ('Qatar'),\n",
              " ('Romania'),\n",
              " ('Russia'),\n",
              " ('Rwanda'),\n",
              " ('Saint Lucia'),\n",
              " ('Saint Vincent and the Grenadines'),\n",
              " ('San Marino'),\n",
              " ('Saudi Arabia'),\n",
              " ('Senegal'),\n",
              " ('Serbia'),\n",
              " ('Seychelles'),\n",
              " ('Singapore'),\n",
              " ('Slovakia'),\n",
              " ('Slovenia'),\n",
              " ('Somalia'),\n",
              " ('South Africa'),\n",
              " ('Spain'),\n",
              " ('Sri Lanka'),\n",
              " ('Sudan'),\n",
              " ('Suriname'),\n",
              " ('Sweden'),\n",
              " ('Switzerland'),\n",
              " ('Taiwan*'),\n",
              " ('Tanzania'),\n",
              " ('Thailand'),\n",
              " ('Togo'),\n",
              " ('Trinidad and Tobago'),\n",
              " ('Tunisia'),\n",
              " ('Turkey'),\n",
              " ('Uganda'),\n",
              " ('Ukraine'),\n",
              " ('United Arab Emirates'),\n",
              " ('United Kingdom'),\n",
              " ('Uruguay'),\n",
              " ('US'),\n",
              " ('Uzbekistan'),\n",
              " ('Venezuela'),\n",
              " ('Vietnam'),\n",
              " ('Zambia'),\n",
              " ('Zimbabwe'),\n",
              " ('Dominica'),\n",
              " ('Grenada'),\n",
              " ('Mozambique'),\n",
              " ('Syria'),\n",
              " ('Timor-Leste'),\n",
              " ('Belize'),\n",
              " ('Laos'),\n",
              " ('Libya'),\n",
              " ('West Bank and Gaza'),\n",
              " ('Guinea-Bissau'),\n",
              " ('Mali'),\n",
              " ('Saint Kitts and Nevis'),\n",
              " ('Kosovo'),\n",
              " ('Burma'),\n",
              " ('MS Zaandam'),\n",
              " ('Botswana'),\n",
              " ('Burundi'),\n",
              " ('Sierra Leone'),\n",
              " ('Malawi'),\n",
              " ('South Sudan'),\n",
              " ('Western Sahara'),\n",
              " ('Sao Tome and Principe'),\n",
              " ('Yemen')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2sY7qoAiY_a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}