{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "covid19 db eda.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPJutxga+CHqmmBIIxYwysN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dangandy/covid/blob/world-map/eda/covid19_db_eda.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SH5IdHQTRBcH",
        "colab_type": "text"
      },
      "source": [
        "# Install"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHhksLw3S-_k",
        "colab_type": "code",
        "outputId": "f797b7e0-4e72-47db-9e6b-2ceccf42197f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "pip install flask_sqlalchemy"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: flask_sqlalchemy in /usr/local/lib/python3.6/dist-packages (2.4.1)\n",
            "Requirement already satisfied: Flask>=0.10 in /usr/local/lib/python3.6/dist-packages (from flask_sqlalchemy) (1.1.2)\n",
            "Requirement already satisfied: SQLAlchemy>=0.8.0 in /usr/local/lib/python3.6/dist-packages (from flask_sqlalchemy) (1.3.16)\n",
            "Requirement already satisfied: click>=5.1 in /usr/local/lib/python3.6/dist-packages (from Flask>=0.10->flask_sqlalchemy) (7.1.1)\n",
            "Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.6/dist-packages (from Flask>=0.10->flask_sqlalchemy) (1.1.0)\n",
            "Requirement already satisfied: Jinja2>=2.10.1 in /usr/local/lib/python3.6/dist-packages (from Flask>=0.10->flask_sqlalchemy) (2.11.2)\n",
            "Requirement already satisfied: Werkzeug>=0.15 in /usr/local/lib/python3.6/dist-packages (from Flask>=0.10->flask_sqlalchemy) (1.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.10.1->Flask>=0.10->flask_sqlalchemy) (1.1.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qgZQrtbyiWo0",
        "colab_type": "text"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MgFUiLqViVDn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# db model\n",
        "from flask import Flask\n",
        "from flask_sqlalchemy import SQLAlchemy\n",
        "\n",
        "# create\n",
        "from datetime import datetime, timedelta\n",
        "import requests\n",
        "\n",
        "# lstm\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random as rn\n",
        "\n",
        "# model\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dense\n",
        "from keras.losses import MeanSquaredLogarithmicError\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# predict\n",
        "from keras.models import load_model\n",
        "import collections"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J4gwFxd_ibPN",
        "colab_type": "text"
      },
      "source": [
        "# db model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGaALGgKS78u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load flask\n",
        "app = Flask(__name__)\n",
        "app.config[\"SQLALCHEMY_DATABASE_URI\"] = \"sqlite:///site.db\"\n",
        "app.config[\"SQLALCHEMY_TRACK_MODIFICATIONS\"] = False\n",
        "\n",
        "# load db\n",
        "db = SQLAlchemy(app)\n",
        "\n",
        "# db models\n",
        "class Stat(db.Model):\n",
        "    id = db.Column(db.String(120), primary_key=True)\n",
        "    country = db.Column(db.String(100), unique=False, nullable=False)\n",
        "    date = db.Column(db.Date, nullable=False)\n",
        "    confirmed = db.Column(db.Integer)\n",
        "    deaths = db.Column(db.Integer)\n",
        "    recovered = db.Column(db.Integer)\n",
        "    confirmed_pred = db.Column(db.Integer)\n",
        "    deaths_pred = db.Column(db.Integer)\n",
        "    recovered_pred = db.Column(db.Integer)\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f\"Stat('{self.country}', '{self.date}', '{self.confirmed}', '{self.deaths}', '{self.recovered}',  '{self.confirmed_pred}', '{self.deaths_pred}', '{self.recovered_pred}')\"\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MKGly5ueinPM",
        "colab_type": "text"
      },
      "source": [
        "# create"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xFNN-2hXSz1Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Create:\n",
        "    def __init__(self):\n",
        "        # variables\n",
        "        self.url = \"https://pomber.github.io/covid19/timeseries.json\"\n",
        "\n",
        "    def extract(self):\n",
        "        # get json data\n",
        "        response = requests.get(self.url)\n",
        "        json = response.json()\n",
        "\n",
        "        # return\n",
        "        return json\n",
        "\n",
        "    def transform(self, json: dict):\n",
        "        # variables\n",
        "        countries = json.keys()\n",
        "        all_data = []\n",
        "\n",
        "        # loop\n",
        "        for country in countries:\n",
        "\n",
        "            # build array of json\n",
        "            for i, stat in enumerate(json[country]):\n",
        "                data = Stat(\n",
        "                    id=f\"{country}{stat['date']}\",\n",
        "                    country=country,\n",
        "                    date=datetime.strptime(stat[\"date\"], \"%Y-%m-%d\").date(),\n",
        "                    confirmed=stat[\"confirmed\"],\n",
        "                    deaths=stat[\"deaths\"],\n",
        "                    recovered=stat[\"recovered\"],\n",
        "                )\n",
        "                all_data.append(data)\n",
        "\n",
        "        # return\n",
        "        return all_data\n",
        "\n",
        "    def load(self, data):\n",
        "        # create db\n",
        "        db.create_all()\n",
        "\n",
        "        # add to db\n",
        "        db.session.bulk_save_objects(data)\n",
        "        db.session.commit()\n",
        "\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    1. Extract JSON from url\n",
        "    2. Transform JSON into: id, country, confirmed, recovered, deaths\n",
        "        - id is in the form of {country}{date}\n",
        "    3. Load object into sqlite database\n",
        "    \"\"\"\n",
        "    create = Create()\n",
        "    json = create.extract()\n",
        "    data = create.transform(json)\n",
        "    create.load(data)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W0-HNWAti1OR",
        "colab_type": "text"
      },
      "source": [
        "# Update"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8pgVz60Ji1-5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Update(Create):\n",
        "    def transform(self, json: dict):\n",
        "        # variables\n",
        "        countries = json.keys()\n",
        "        update_data = []\n",
        "\n",
        "        # we only want to update everything from yesterday onwards..\n",
        "        update_day = datetime.now().date() + timedelta(days=-1)\n",
        "\n",
        "        # loop and build array of Stat\n",
        "        for country in countries:\n",
        "            for i, stat in enumerate(json[country]):\n",
        "                date = datetime.strptime(stat[\"date\"], \"%Y-%m-%d\").date()\n",
        "\n",
        "                if date >= update_day:\n",
        "                    update_data.append(\n",
        "                        Stat(\n",
        "                            id=f\"{country}{stat['date']}\",\n",
        "                            country=country,\n",
        "                            date=date,\n",
        "                            confirmed=stat[\"confirmed\"],\n",
        "                            deaths=stat[\"deaths\"],\n",
        "                            recovered=stat[\"recovered\"],\n",
        "                        )\n",
        "                    )\n",
        "\n",
        "        # return\n",
        "        return update_data\n",
        "\n",
        "    def load(self, data):\n",
        "        \"\"\"\n",
        "        insert if doesn't exist, update otherwise\n",
        "        \"\"\"\n",
        "        # loop\n",
        "        for stat in data:\n",
        "            query = Stat.query.get({\"id\": stat.id})\n",
        "            if query:\n",
        "                query.confirmed = stat.confirmed\n",
        "                query.deaths = stat.deaths\n",
        "                query.recovered = stat.recovered\n",
        "            else:\n",
        "                db.session.add(stat)\n",
        "\n",
        "        # commit\n",
        "        db.session.commit()\n",
        "\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    1. Extract new data from url\n",
        "    2. get last 2 days data ( data here is updated hourly )\n",
        "    3. insert / update into db\n",
        "    \"\"\"\n",
        "    update = Update()\n",
        "    json = update.extract()\n",
        "    last_days = update.transform(json)\n",
        "    update.load(last_days)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Yel-EWmS6-F",
        "colab_type": "text"
      },
      "source": [
        "# build lstm model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1fYQrZRTTM-I",
        "colab_type": "code",
        "outputId": "d0182650-54e4-4eb5-ce94-6703afece3ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "class Lstm:\n",
        "    def extract(self) -> pd.DataFrame:\n",
        "        \"\"\"\n",
        "        extract data from database and output into dataframe\n",
        "        \"\"\"\n",
        "        # grab all record from stat table\n",
        "        df = pd.read_sql_table(\"stat\", \"sqlite:///site.db\")\n",
        "\n",
        "        # return\n",
        "        return df\n",
        "\n",
        "    def transform(self, df: pd.DataFrame) -> pd.DataFrame:\n",
        "        \"\"\"\n",
        "        transforms done to dataframe:\n",
        "        - calculate the difference of each metric\n",
        "        - onehotencode countries\n",
        "        \"\"\"\n",
        "        # get diff\n",
        "        df[\"confirmed_diff\"] = np.where(\n",
        "            df.country == df.country.shift(), df.confirmed - df.confirmed.shift(), 0\n",
        "        )\n",
        "        df[\"recovered_diff\"] = np.where(\n",
        "            df.country == df.country.shift(), df.recovered - df.recovered.shift(), 0\n",
        "        )\n",
        "        df[\"deaths_diff\"] = np.where(\n",
        "            df.country == df.country.shift(), df.deaths - df.deaths.shift(), 0\n",
        "        )\n",
        "\n",
        "        # encode country with pd.dummies\n",
        "        dummies = pd.get_dummies(df.country)\n",
        "        dummies[\"id\"] = df.id\n",
        "        df = pd.merge(df, dummies, on=[\"id\"])\n",
        "\n",
        "        # return\n",
        "        return df\n",
        "\n",
        "    def load(\n",
        "        self,\n",
        "        df: pd.DataFrame,\n",
        "        metric=\"confirmed\",\n",
        "        win_size=7,\n",
        "        epochs=5,\n",
        "        batch_size=32,\n",
        "        save=False,\n",
        "    ) -> Sequential:\n",
        "        \"\"\"\n",
        "        load dataframe into sequential\n",
        "        \"\"\"\n",
        "        # variables\n",
        "        x, y = [], []\n",
        "        countries = db.session.query(Stat.country).distinct().all()\n",
        "\n",
        "        # countries come in the form of [('Afghanistan',), ('Albania',), ... ]\n",
        "        for (country,) in countries:\n",
        "            country_df = df[df.country == country]\n",
        "            series = list(country_df[metric])\n",
        "            for i in range(0, len(series) - win_size):\n",
        "                end = i + win_size\n",
        "                series_x, series_y = series[i:end], series[end]\n",
        "                if series_y:\n",
        "                    x.append(series_x)\n",
        "                    y.append(series_y)\n",
        "        X, y = np.array(x), np.array(y)\n",
        "\n",
        "        # TTS\n",
        "        X_train, X_val, y_train, y_val = train_test_split(\n",
        "            X, y, test_size=0.2, random_state=42\n",
        "        )\n",
        "\n",
        "        # preprocess\n",
        "        X_train = X_train.reshape(X_train.shape[0], 1, X_train.shape[1])\n",
        "        X_val = X_val.reshape(X_val.shape[0], 1, X_val.shape[1])\n",
        "\n",
        "        # build model\n",
        "        model = Sequential()\n",
        "        model.add(\n",
        "            LSTM(\n",
        "                100,\n",
        "                activation=\"relu\",\n",
        "                input_shape=(1, win_size),\n",
        "                return_sequences=True,\n",
        "            )\n",
        "        )\n",
        "        model.add(LSTM(150, activation=\"relu\"))\n",
        "        model.add(Dense(1, activation=\"relu\"))\n",
        "\n",
        "        # Compile Model\n",
        "        model.compile(optimizer=\"adam\", loss=MeanSquaredLogarithmicError())\n",
        "\n",
        "        # Fit Model\n",
        "        model.fit(\n",
        "            X_train,\n",
        "            y_train,\n",
        "            epochs=epochs,\n",
        "            batch_size=batch_size,\n",
        "            validation_data=(X_val, y_val),\n",
        "            verbose=2,\n",
        "            shuffle=True,\n",
        "        )\n",
        "\n",
        "        # Export Model\n",
        "        if save:\n",
        "            model.save(\"lstm_model.h5\")\n",
        "\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    run code\n",
        "    \"\"\"\n",
        "    # Set random state for Keras\n",
        "    np.random.seed(42)\n",
        "    rn.seed(12345)\n",
        "\n",
        "    # build model and save it\n",
        "    model = Lstm()\n",
        "    df = model.extract()\n",
        "    df = model.transform(df)\n",
        "    lstm = model.load(df, save=True)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 7355 samples, validate on 1839 samples\n",
            "Epoch 1/5\n",
            " - 2s - loss: 0.5780 - val_loss: 0.0373\n",
            "Epoch 2/5\n",
            " - 1s - loss: 0.0369 - val_loss: 0.0362\n",
            "Epoch 3/5\n",
            " - 1s - loss: 0.0357 - val_loss: 0.0348\n",
            "Epoch 4/5\n",
            " - 1s - loss: 0.0351 - val_loss: 0.0348\n",
            "Epoch 5/5\n",
            " - 1s - loss: 0.0347 - val_loss: 0.0348\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IkDoEMhuS0SE",
        "colab_type": "text"
      },
      "source": [
        "## predict"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sY_i90ZPT-Um",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Predict:\n",
        "    def __init__(self):\n",
        "        # start date is 7 days ago\n",
        "        self.today = datetime.now().date()\n",
        "        self.start_date = self.today + timedelta(days=-7)\n",
        "\n",
        "    def get_data(self):\n",
        "        \"\"\"\n",
        "        get last \"7\" days of data\n",
        "        \"\"\"\n",
        "        # get all prediction of country\n",
        "        result = Stat.query.filter(\n",
        "            Stat.date >= self.start_date, Stat.date < self.today\n",
        "        ).all()\n",
        "\n",
        "        # create a map for each country and their 7 latest record\n",
        "        memo = collections.defaultdict(list)\n",
        "        for stat in result:\n",
        "            memo[stat.country].append(stat.confirmed)\n",
        "\n",
        "        # return\n",
        "        countries = memo.keys()\n",
        "        X = np.array([memo[country] for country in countries])\n",
        "        X = X.reshape(X.shape[0], 1, X.shape[1])\n",
        "        return countries, X\n",
        "\n",
        "    def predict(self, countries, X, model):\n",
        "        \"\"\"\n",
        "        predict, then predict again\n",
        "        \"\"\"\n",
        "        # variables\n",
        "        data = []\n",
        "\n",
        "        # predict - we'll be shifting x every iteration because predict output 1 value\n",
        "        for i in range(7):\n",
        "            _X = np.array([x[i : 7 + i] for [x] in X])\n",
        "            _X = _X.reshape(_X.shape[0], 1, _X.shape[1])\n",
        "            y_pred = model.predict(_X)\n",
        "\n",
        "            # add new prediction to x\n",
        "            X = np.array([np.append(x, y_pred[j]) for j, [x] in enumerate(X)])\n",
        "            X = X.reshape(X.shape[0], 1, X.shape[1])\n",
        "\n",
        "        # add predictions into database..\n",
        "        y_pred = [x[7:14] for [x] in X]\n",
        "        for country, prediction in zip(countries, y_pred):\n",
        "            for i, pred in enumerate(prediction):\n",
        "                pred_date = self.today + timedelta(days=i)\n",
        "                data.append(\n",
        "                    Stat(\n",
        "                        id=f\"{country}{pred_date}\",\n",
        "                        country=country,\n",
        "                        date=pred_date,\n",
        "                        confirmed_pred=int(pred),\n",
        "                    )\n",
        "                )\n",
        "\n",
        "        # return\n",
        "        return data\n",
        "\n",
        "    def load(self, data):\n",
        "        \"\"\"\n",
        "        insert if doesn't exist, update otherwise\n",
        "        \"\"\"\n",
        "        # loop\n",
        "        for stat in data:\n",
        "            query = Stat.query.get({\"id\": stat.id})\n",
        "            if query:\n",
        "                query.confirmed = stat.confirmed\n",
        "                query.deaths = stat.deaths\n",
        "                query.recovered = stat.recovered\n",
        "                query.confirmed_pred = (\n",
        "                    stat.confirmed_pred if stat.confirmed_pred else None\n",
        "                )\n",
        "                query.deaths_pred = stat.deaths_pred if stat.deaths_pred else None\n",
        "                query.recovered_pred = (\n",
        "                    stat.recovered_pred if stat.recovered_pred else None\n",
        "                )\n",
        "            else:\n",
        "                db.session.add(stat)\n",
        "\n",
        "        # commit\n",
        "        db.session.commit()\n",
        "\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    run code\n",
        "    \"\"\"\n",
        "    # variables\n",
        "    predict = Predict()\n",
        "\n",
        "    # load model\n",
        "    lstm = load_model(\"lstm_model.h5\")\n",
        "    countries, X = predict.get_data()\n",
        "    data = predict.predict(countries, X, lstm)\n",
        "\n",
        "    # save to db\n",
        "    predict.load(data)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SreC-DmbmIif",
        "colab_type": "text"
      },
      "source": [
        "# api methods"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sRP9qiCY1WGX",
        "colab_type": "text"
      },
      "source": [
        "Broken up by individual functions because we can't use flask here\n",
        "\n",
        "Using 'Canada' as default"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_p0YBDED154i",
        "colab_type": "text"
      },
      "source": [
        "## Country Stats"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bP9GqM-j13kr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "578543f7-0702-417a-b857-aa0f07e200b6"
      },
      "source": [
        "# search db\n",
        "    result = (\n",
        "        Stat.query.filter(Stat.confirmed != None, Stat.country == 'Canada')\n",
        "        .order_by(Stat.date.desc())\n",
        "        .first()\n",
        "    )\n",
        "\n",
        "{\n",
        "\"confirmed\": result.confirmed,\n",
        "    \"deaths\": result.deaths,\n",
        "    \"recovered\": result.recovered,\n",
        "}"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'confirmed': 41648, 'deaths': 2075, 'recovered': 14454}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k0VE-eBM2HZj",
        "colab_type": "text"
      },
      "source": [
        "## World Stats"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6FKAy4jj2ITy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f35adb9e-2e9d-48f4-ed36-5d9473a09889"
      },
      "source": [
        "# search db\n",
        "result = (\n",
        "    db.session.query(\n",
        "        db.func.max(Stat.confirmed).label(\"confirmed\"),\n",
        "        db.func.max(Stat.recovered).label(\"recovered\"),\n",
        "        db.func.max(Stat.deaths).label(\"deaths\"),\n",
        "    )\n",
        "    .filter(Stat.confirmed != None)\n",
        "    .order_by(Stat.date.desc())\n",
        "    .group_by(Stat.country)\n",
        "    .all()\n",
        ")\n",
        "\n",
        "# get sums because I don't know how to do it in SQLAlchemy..\n",
        "confirmed = sum(r[0] for r in result)\n",
        "recovered = sum(r[1] for r in result)\n",
        "deaths = sum(r[2] for r in result)\n",
        "\n",
        "# return\n",
        "{\"confirmed\": confirmed, \"recovered\": recovered, \"deaths\": deaths}"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'confirmed': 2625585, 'deaths': 183025, 'recovered': 710455}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fGHeVvLO2SXg",
        "colab_type": "text"
      },
      "source": [
        "## Country history"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_tWijrz62UAP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "4612f64f-afe3-4f71-cc3a-97c6815f5d7e"
      },
      "source": [
        "# varialbes\n",
        "array = []\n",
        "\n",
        "# use filter to get all data\n",
        "result = Stat.query.filter_by(country='Canada').all()\n",
        "\n",
        "# build array\n",
        "for record in result:\n",
        "    array.append(\n",
        "        {\n",
        "            \"confirmed\": record.confirmed,\n",
        "            \"date\": record.date,\n",
        "            \"recovered\": record.recovered,\n",
        "            \"deaths\": record.deaths,\n",
        "            \"confirmed_pred\": record.confirmed_pred,\n",
        "        }\n",
        "    )\n",
        "\n",
        "# return\n",
        "{\"result\": array[:3]}"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'result': [{'confirmed': 0,\n",
              "   'confirmed_pred': None,\n",
              "   'date': datetime.date(2020, 1, 22),\n",
              "   'deaths': 0,\n",
              "   'recovered': 0},\n",
              "  {'confirmed': 0,\n",
              "   'confirmed_pred': None,\n",
              "   'date': datetime.date(2020, 1, 23),\n",
              "   'deaths': 0,\n",
              "   'recovered': 0},\n",
              "  {'confirmed': 0,\n",
              "   'confirmed_pred': None,\n",
              "   'date': datetime.date(2020, 1, 24),\n",
              "   'deaths': 0,\n",
              "   'recovered': 0}]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MM4osaU2jGo",
        "colab_type": "text"
      },
      "source": [
        "## World History"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXlq-d59z_xM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "outputId": "0f0d270d-ec3a-4578-abeb-a94df2a0f1c5"
      },
      "source": [
        "# variables\n",
        "array = []\n",
        "\n",
        "# query\n",
        "result = (\n",
        "    db.session.query(\n",
        "        Stat.country,\n",
        "        db.func.max(Stat.confirmed).label(\"confirmed\"),\n",
        "        Stat.recovered,\n",
        "        Stat.deaths,\n",
        "        Stat.confirmed_pred,\n",
        "    )\n",
        "    .group_by(Stat.country)\n",
        "    .all()\n",
        ")\n",
        "\n",
        "# build array\n",
        "for record in result:\n",
        "    array.append(\n",
        "        {\n",
        "            \"country\": record.country,\n",
        "            \"confirmed\": record.confirmed,\n",
        "            \"recovered\": record.recovered,\n",
        "            \"deaths\": record.deaths,\n",
        "            \"confirmed_pred\": record.confirmed_pred,\n",
        "        }\n",
        "    )\n",
        "\n",
        "# return\n",
        "{\"result\": array[-5:]}"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'result': [{'confirmed': 474,\n",
              "   'confirmed_pred': None,\n",
              "   'country': 'West Bank and Gaza',\n",
              "   'deaths': 4,\n",
              "   'recovered': 71},\n",
              "  {'confirmed': 6,\n",
              "   'confirmed_pred': None,\n",
              "   'country': 'Western Sahara',\n",
              "   'deaths': 0,\n",
              "   'recovered': 0},\n",
              "  {'confirmed': 1,\n",
              "   'confirmed_pred': None,\n",
              "   'country': 'Yemen',\n",
              "   'deaths': 0,\n",
              "   'recovered': 0},\n",
              "  {'confirmed': 74,\n",
              "   'confirmed_pred': None,\n",
              "   'country': 'Zambia',\n",
              "   'deaths': 3,\n",
              "   'recovered': 35},\n",
              "  {'confirmed': 28,\n",
              "   'confirmed_pred': None,\n",
              "   'country': 'Zimbabwe',\n",
              "   'deaths': 3,\n",
              "   'recovered': 2}]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    }
  ]
}